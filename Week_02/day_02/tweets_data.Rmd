---
title: "R Notebook"
output: html_notebook
---
```{r}
library(tidyverse)
library(CodeClanData)
library(janitor)
library(tidyr)
```

q1
```{r}
Tweet_data <- read_csv('data/code_clan_tweets.csv')

nrow(Tweet_data)
ncol(Tweet_data)

names(Tweet_data)

```
q2
```{r}
Tweet_data
Favourite_tweets <- Tweet_data %>% 
  select(tweet_id, favorite_count, user_id, is_quote) %>% 
  filter(is_quote == TRUE) %>% 
  summarise(sum(favorite_count))

Favourite_tweets
```

```{r}
Avg_retweets <- Tweet_data %>% 
  select(retweet_count, retweet_source) %>% 
  group_by(retweet_count) %>%
  split(retweet_count, retweet_source) %>% 
  filter(is_quote == TRUE) %>% 
  summarise(mean_retweets = mean(retweet_count)) #%>%

   

```
q3
```{r}
#Kate's code
code_clan_tweets <- Tweet_data %>% 
  filter(is_quote == FALSE) %>% 
  group_by(source) %>% 
  summarise(mean(retweet_count))
```

```{r}
Tweet_data %>%   
  filter(is_quote == FALSE) %>% 
  group_by(source) %>% 
  summarise(mean_retweets = mean(retweet_count))
```

q4
```{r}
Overall_likes <- Tweet_data %>% 
  select(favorite_count, tweet_id, user_id, source) %>% 
  group_by(source) %>% 
  summarise(most_likes = max(favorite_count)) %>% 
  arrange(desc(most_likes))
  
```
q5
```{r}
Mean_characters <- Tweet_data %>% 
  select(text, display_text_width, tweet_id) %>% 
  group_by(display_text_width) %>% 
  summarise(mean_text = mean(display_text_width)) %>% 
  arrange(desc(mean_text))

Mean_characters  
```

```{r}
code_clan_tweets_text <- Tweet_data %>% 
  
```

```{r}
tweet_split <- Tweet_data %>% 
  pull(text) %>% 
  str_split("") %>% 
  flatten_chr()

lengths(tweet_split) / nrow(Tweet_data)
```

```{r}
code_clan_tweets_text <- Tweet_data %>% 
  mutate(count_str_length = str_length(text)) %>% 
  select(count_str_length, display_text_width)

code_clan_tweets_text %>% 
  summarise(average = mean(count_str_length))
  
```

q6
```{r}
CodeClan_info <- read_csv('data/code_clan_info.csv')

head(CodeClan_info)
head(Tweet_data)

CodeClan_status <- Tweet_data %>% 
  inner_join(CodeClan_info, by = "tweet_id")

CodeClan_status
```

q7
```{r}
#Tweet_data
CodeClan_Hashtags <- CodeClan_status %>% 
  select(tweet_id, hashtags) %>% 
  drop_na(hashtags) %>% 
  mutate(hashtags = str_to_lower(hashtags))
```

Answers from CodeClan_notes
```{r}
Tweet_data %>%
  mutate(media_type = coalesce(media_type, "text")) %>%
  group_by(media_type) %>%
  summarise(favourite_count_total = sum(favorite_count)) %>%
  arrange(desc(favourite_count_total))
```

```{r}
code_clan_tweets_text <- Tweet_data %>%
  mutate(count_str_length = str_length(text)) %>%
  select(count_str_length, display_text_width)

code_clan_tweets_text
```

```{r}
codeclan_info <- read_csv("data/code_clan_info.csv")
names(codeclan_info)
codeclan_all <- left_join(Tweet_data, codeclan_info, by = "tweet_id")
```

```{r}
codeclan_hashtags <- codeclan_all%>% 
  select(tweet_id, hashtags) %>%
  mutate(lowcase_hashtag = str_to_lower(hashtags)) %>%
  select(-hashtags) %>%
  drop_na(lowcase_hashtag)

codeclan_hashtags
```

```{r}
hashtags_multiple <- codeclan_hashtags %>% 
  mutate(first_letters = str_sub(lowcase_hashtag, 1, 2)) %>%
  filter(str_detect(first_letters, "c\\("))

hashtags_multiple
```

```{r}
Tweet_data %>%
  mutate(lowcase_tweets = str_to_lower(text)) %>%
  filter(str_detect(lowcase_tweets, "edinburgh")) %>%
  summarise(count = n())
```

```{r}
user_pattern <- "@[a-zA-Z0-9_]+"
tweets <- Tweet_data %>% 
  select(text)
head(str_extract_all(tweets$text, user_pattern))
```

```{r}
code_clan_joined %>% 
  mutate(text = str_to_lower(text)) %>% 
  summarise(contains_pattern = sum(str_detect(text, "edinburgh")))
```

```{r}
codeclan_edinburgh <- CodeClan_info %>% 
  select(text) %>% 
  mutate(text = c(str_to_lower(text)), 
         edinburgh_detect = str_count(text, "[Ee]dinburgh")) %>% 
  summarise(sum(edinburgh_detect))
```

